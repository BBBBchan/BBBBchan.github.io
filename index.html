---
layout: home
profile_picture:
  src: /assets/img/boyuansun.png
  alt: website picture
items:
- title: See What I Mean&#58; Aligning Vision and Language Representations for Video Fine-grained Object Understanding
  image:
    src: assets/img/work/swim.png
    alt: arxiv
  author: <b>Boyuan Sun</b>, Bo-Wen Yin, Yuan-Ming Li, Xihan Wei, Qibin Hou
  pubname: IEEE Computer Vision and Pattern Recognition 2026 <b>(CVPR 2026)</b>
  bibtex: 
- title: GeoAgent&#58; Learning to Geolocate Everywhere with Reinforced Geographic Characteristics
  image:
    src: assets/img/work/geoagent.png
    alt: arxiv
  author: Modi Jin, Yiming Zhang, <b>Boyuan Sun</b>, Dingwen Zhang, Ming-Ming Cheng, Qibin Hou 
  pubname: IEEE Computer Vision and Pattern Recognition 2026 <b>(CVPR 2026)</b>
  code: https://github.com/HVision-NKU/GeoAgent  
  paper: https://arxiv.org/abs/2602.12617  
  project: https://ghost233lism.github.io/GeoAgent-page/  
  demo: https://huggingface.co/spaces/ghost233lism/GeoAgent  
  hf: https://huggingface.co/ghost233lism/GeoAgent  
  bibtex: 
- title: Depth Anything at Any Condition
  image:
    src: assets/img/work/depthanythingac_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Modi Jin*,  Bowen Yin, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HVision-NKU/DepthAnythingAC  
  paper: https://arxiv.org/abs/2507.01634  
  project: https://ghost233lism.github.io/depthanything-AC-page/  
  demo: https://huggingface.co/spaces/ghost233lism/DepthAnything-AC  
  hf: https://huggingface.co/ghost233lism/DepthAnything-AC  
  bibtex: 
- title: LLaVA-Scissor&#58; token Compression with Semantic Connected Components for Video LLMs
  image:
    src: assets/img/work/llavascissor_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Jiaxing Zhao*,  Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HumanMLLM/LLaVA-Scissor  
  paper: https://arxiv.org/abs/2506.21862  
  hf: https://huggingface.co/BBBBCHAN/LLaVA-Scissor-baseline-7B  
  bibtex: 
- title: HumanOmniV2&#58; From Understanding to Omni-Modal Reasoning with Context
  image:
    src: assets/img/work/humanomniv2_pipeline.png
    alt: arxiv
  author: Qize Yang*, Shimin Yao*, Weixuan Chen*, Shenghao Fu, Detao Bai, Jiaxing Zhao, <b>Boyuan Sun</b>, Bowen Yin, Xihan Wei, Jingren Zhou
  pubname: Technical Report
  code: https://github.com/HumanMLLM/HumanOmniV2  
  paper: https://arxiv.org/abs/2506.21277  
  hf: https://huggingface.co/PhilipC/HumanOmniV2  
  bibtex: 
- title: HumanOmni&#58; A Large Vision-Speech Language Model for Human-Centric Video Understanding
  image:
    src: assets/img/work/humanomni_pipeline.png
    alt: arxiv
  author: Jiaxing Zhao*, Qize Yang*, Yixing Peng*, Detao Bai* Shimin Yao*, <b>Boyuan Sun</b>, Xiang Chen, Shenghao Fu, Weixuan Chen, Xihan Wei, Liefeng Bo#
  pubname: Technical Report
  code: https://github.com/HumanMLLM/HumanOmni  
  paper: https://arxiv.org/abs/2501.15111  
  bibtex: 
- title: LLaVA-Octopus&#58; Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding
  image:
    src: assets/img/work/octopus_logo.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/Jiaxing-star/LLaVA-Octopus  
  paper: https://arxiv.org/abs/2501.05067  
  bibtex: 
- title: Facial Dynamics in Video&#58; Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness
  image:
    src: /assets/img/work/DFEC_method.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei
  pubname: Association for the Advancement of Artificial Intelligence 2026 <b>(AAAI 2026)</b>
  code: https://github.com/Jiaxing-star/FacialDynamic  
  paper: https://arxiv.org/abs/2501.07978  
  bibtex:
- title: AODRaw&#58; Towards RAW Object Detection in Diverse Conditions
  image:
    src: assets/img/work/aodraw_teaser.png
    alt: arxiv
  author: Zhong-Yu Li, Xin Jin, <b>Boyuan Sun</b>, Chun-Le Guo, Ming-Ming Cheng#
  pubname: IEEE Computer Vision and Pattern Recognition 2025  <b>(CVPR 2025 Highlight)</b>
  code: https://github.com/lzyhha/AODRaw  
  paper: https://arxiv.org/abs/2411.15678  
  bibtex:
- title: CorrMatch&#58; Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation
  image:
    src: /assets/img/work/corrmatch_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun</b>, Yuqi Yang, Weifeng Yuan, Le Zhang, Ming-Ming Cheng, Qibin Hou#
  pubname: IEEE Computer Vision and Pattern Recognition 2024 <b>(CVPR 2024)</b>
  code: https://github.com/BBBBchan/CorrMatch  
  paper: https://arxiv.org/abs/2306.04300  
  bibtex:
- title: CamoFormer&#58; Masked Separable Attention for Camouflaged Object Detection
  image:
    src: /assets/img/work/CamoFormer_pipeline.png
    alt: arxiv
  author: Bowen Yin, Xuying Zhang, Qibin Hou, <b>Bo-Yuan Sun</b>, Deng-Ping Fan, & Luc Van Gool.
  pubname: Arxiv preprint 2022
  code: https://github.com/HVision-NKU/CamoFormer  
  paper: https://arxiv.org/pdf/2212.06570.pdf  
  bibtex:
---

<style>
  /* ========== Âü∫Á°ÄÂèòÈáè ========== */
  :root {
    --primary-gradient: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    --card-shadow: 0 4px 6px rgba(0,0,0,0.07);
    --card-shadow-hover: 0 12px 24px rgba(0,0,0,0.12);
    --border-color: #e2e8f0;
    --text-primary: #2d3748;
    --text-secondary: #4a5568;
    --text-muted: #718096;
    --bg-soft: #f7fafc;
  }

  /* ========== ‰∏™‰∫∫ÁÆÄ‰ªãÂå∫Âüü ========== */
  .profile-section {
    display: flex;
    align-items: flex-start;
    gap: 2rem;
    margin-bottom: 2.5rem;
    flex-wrap: wrap;
  }

  /* üî≤ ÊñπÂΩ¢Â§¥ÂÉèÊ†∑Âºè */
  .profile-picture {
    flex-shrink: 0;
  }

  .profile-picture img {
    width: 160px;
    height: 160px;
    border-radius: 16px;  /* üî≤ ÊñπÂΩ¢Â∏¶ÂúÜËßí */
    object-fit: cover;
    border: 4px solid #e0e0e0;
    box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
  }

  .profile-picture img:hover {
    transform: scale(1.03);
    box-shadow: 0 8px 20px rgba(0,0,0,0.15);
  }

  .profile-content {
    flex: 1;
    min-width: 280px;
  }

  .profile-content p {
    line-height: 1.8;
    color: var(--text-secondary);
    margin-bottom: 1rem;
    text-align: justify;
  }

  .contact-info {
    margin-top: 1.5rem;
    padding: 1.2rem 1.5rem;
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    border-radius: 12px;
    display: flex;
    flex-wrap: wrap;
    gap: 0.8rem 1.5rem;
    align-items: center;
  }

  .contact-info i {
    color: #667eea;
    margin-right: 0.4rem;
    width: 18px;
  }

  .contact-info a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: color 0.3s ease;
    display: inline-flex;
    align-items: center;
    gap: 0.4rem;
  }

  .contact-info a:hover {
    color: #764ba2;
    text-decoration: underline;
  }

  .contact-item {
    display: flex;
    align-items: center;
    gap: 0.4rem;
  }

  /* ========== Á´†ËäÇÈÄöÁî®Ê†∑Âºè ========== */
  .section-header {
    font-size: 1.8rem;
    font-weight: 700;
    color: var(--text-primary);
    margin: 2.5rem 0 1.2rem 0;
    position: relative;
    padding-bottom: 0.5rem;
  }

  .section-header::after {
    content: '';
    position: absolute;
    bottom: 0;
    left: 0;
    width: 50px;
    height: 4px;
    background: var(--primary-gradient);
    border-radius: 2px;
  }

  .section-note {
    color: var(--text-muted);
    font-size: 0.9rem;
    margin-bottom: 1.5rem;
    font-style: italic;
  }

  /* ========== ÂÆû‰π†ÁªèÂéÜÊ†∑ÂºèÔºàÂ∏¶LogoÔºâ ========== */
  .experience-grid {
    display: grid;
    grid-template-columns: repeat(auto-fit, minmax(320px, 1fr));
    gap: 1.2rem;
    margin-bottom: 2.5rem;
  }

  .exp-card {
    background: white;
    border-radius: 14px;
    padding: 1.3rem;
    border: 1px solid var(--border-color);
    box-shadow: var(--card-shadow);
    transition: all 0.3s ease;
    position: relative;
    overflow: hidden;
    display: flex;
    flex-direction: column;
  }

  .exp-card::before {
    content: '';
    position: absolute;
    top: 0;
    left: 0;
    right: 0;
    height: 3px;
    background: var(--primary-gradient);
  }

  .exp-card:hover {
    transform: translateY(-3px);
    box-shadow: var(--card-shadow-hover);
  }

  .exp-header {
    display: flex;
    justify-content: space-between;
    align-items: center;
    margin-bottom: 0.8rem;
    gap: 0.8rem;
    flex-wrap: wrap;
  }

  .exp-logo-wrapper {
    display: flex;
    align-items: center;
    gap: 0.8rem;
    flex: 1;
  }

  .exp-logo {
    width: 40px;
    height: 40px;
    border-radius: 8px;
    object-fit: contain;
    background: var(--bg-soft);
    padding: 4px;
    border: 1px solid var(--border-color);
  }

  .exp-company {
    font-size: 1.05rem;
    font-weight: 600;
    color: var(--text-primary);
  }

  .exp-period {
    background: linear-gradient(135deg, #667eea15 0%, #764ba215 100%);
    color: #667eea;
    padding: 0.25rem 0.7rem;
    border-radius: 16px;
    font-size: 0.8rem;
    font-weight: 500;
    white-space: nowrap;
  }

  .exp-role {
    color: #667eea;
    font-weight: 500;
    margin-bottom: 0.4rem;
    font-size: 0.9rem;
  }

  .exp-description {
    color: var(--text-secondary);
    line-height: 1.6;
    font-size: 0.9rem;
    margin-bottom: 0.8rem;
    flex: 1;
  }

  .exp-tags {
    display: flex;
    flex-wrap: wrap;
    gap: 0.4rem;
  }

  .exp-tag {
    background: var(--bg-soft);
    color: var(--text-secondary);
    padding: 0.2rem 0.5rem;
    border-radius: 5px;
    font-size: 0.75rem;
    border: 1px solid var(--border-color);
  }

  /* ========== Âá∫ÁâàÁâ©Âç°ÁâáÊ†∑ÂºèÔºàÊõ¥Á¥ßÂáëÂ∏ÉÂ±ÄÔºâ ========== */
  .publications-grid {
    display: grid;
    /* üîß ÂáèÂ∞èÊúÄÂ∞èÂÆΩÂ∫¶Ôºå‰∏ÄË°åÂèØÊòæÁ§∫Êõ¥Â§öÂç°Áâá */
    grid-template-columns: repeat(auto-fill, minmax(480px, 1fr));
    gap: 1.5rem;
  }

  .pub-card {
    background: white;
    border-radius: 14px;
    overflow: hidden;
    box-shadow: var(--card-shadow);
    transition: all 0.3s ease;
    border: 1px solid var(--border-color);
    display: flex;
    flex-direction: column;
    height: 100%;
  }

  .pub-card:hover {
    transform: translateY(-4px);
    box-shadow: var(--card-shadow-hover);
  }

  /* üîß ÂõæÁâáÂå∫Âüü‰ºòÂåñ */
  .pub-image {
    width: 100%;
    height: 180px;  /* üîß Á®çÂæÆÈôç‰ΩéÈ´òÂ∫¶ÔºåÊõ¥Á¥ßÂáë */
    background: var(--bg-soft);
    display: flex;
    align-items: center;
    justify-content: center;
    padding: 0.8rem;
    box-sizing: border-box;
    overflow: hidden;
  }

  .pub-image img {
    max-width: 100%;
    max-height: 100%;
    width: auto;
    height: auto;
    object-fit: contain;
    transition: transform 0.3s ease;
  }

  .pub-card:hover .pub-image img {
    transform: scale(1.02);
  }

  .pub-content {
    padding: 1.2rem;
    flex: 1;
    display: flex;
    flex-direction: column;
  }

  .pub-title {
    font-size: 1rem;
    font-weight: 600;
    color: var(--text-primary);
    margin-bottom: 0.6rem;
    line-height: 1.4;
  }

  .pub-authors {
    color: var(--text-secondary);
    font-size: 0.85rem;
    margin-bottom: 0.4rem;
    line-height: 1.4;
  }

  .pub-venue {
    color: #667eea;
    font-weight: 600;
    font-size: 0.8rem;
    margin-bottom: 0.8rem;
  }

  .pub-links {
    display: flex;
    flex-wrap: wrap;
    gap: 0.4rem;
    margin-top: auto;
  }

  .pub-link {
    display: inline-flex;
    align-items: center;
    gap: 0.25rem;
    padding: 0.3rem 0.6rem;
    background: var(--primary-gradient);
    color: white;
    text-decoration: none;
    border-radius: 5px;
    font-size: 0.8rem;
    font-weight: 500;
    transition: all 0.3s ease;
    box-shadow: 0 2px 4px rgba(102, 126, 234, 0.25);
  }

  .pub-link:hover {
    transform: translateY(-1px);
    box-shadow: 0 4px 8px rgba(102, 126, 234, 0.35);
  }

  .pub-link.disabled {
    background: #e2e8f0;
    color: var(--text-muted);
    cursor: not-allowed;
    box-shadow: none;
  }

  .pub-link.disabled:hover {
    transform: none;
  }

  /* ========== ÂìçÂ∫îÂºèËÆæËÆ° ========== */
  @media (max-width: 992px) {
    .publications-grid {
      grid-template-columns: repeat(auto-fill, minmax(420px, 1fr));
    }
  }

  @media (max-width: 768px) {
    .profile-section {
      flex-direction: column;
      align-items: center;
      text-align: center;
    }

    .profile-content {
      min-width: 100%;
    }

    .profile-content p {
      text-align: left;
    }

    .contact-info {
      justify-content: center;
    }

    .experience-grid,
    .publications-grid {
      grid-template-columns: 1fr;
      gap: 1.2rem;
    }

    .pub-image {
      height: 160px;
    }

    .exp-header {
      flex-direction: column;
      align-items: flex-start;
    }

    .exp-period {
      align-self: flex-start;
    }

    .exp-logo-wrapper {
      width: 100%;
    }
  }

  @media (max-width: 480px) {
    .profile-picture img {
      width: 140px;
      height: 140px;
    }

    .section-header {
      font-size: 1.5rem;
    }

    .pub-title {
      font-size: 0.95rem;
    }
  }

  /* ========== ÂÖ∂‰ªñ‰ºòÂåñ ========== */
  html {
    scroll-behavior: smooth;
  }

  ::-webkit-scrollbar {
    width: 8px;
  }

  ::-webkit-scrollbar-track {
    background: #f1f1f1;
  }

  ::-webkit-scrollbar-thumb {
    background: #667eea;
    border-radius: 4px;
  }

  ::-webkit-scrollbar-thumb:hover {
    background: #764ba2;
  }
</style>

<!-- ‰∏™‰∫∫ÁÆÄ‰ªãÂå∫Âüü -->
<div class="profile-section">
  <div class="profile-picture">
    {% if page.profile_picture %}
    <img src="{{ page.profile_picture.src | absolute_url }}" alt="{{ page.profile_picture.alt }}">
    {% endif %}
  </div>
  <div class="profile-content">
    <p>
      Boyuan Sun (Â≠ôÂçöËøú) is currently a 3rd year Ph.D. candidate at Nankai University,
      supervised by Prof. <a href="https://houqb.github.io/">Qibin Hou</a> and Prof. <a href="https://mmcheng.net/cmm">Ming-Ming Cheng</a>. He received his bachelor's degree from the School of Computer Science and Technology at Xidian University in 2021. And now he is taking the Master-Ph.D. combined program in Nankai University.
      His research interests include Computer Vision and Multimodal Large Language Model, particularly focusing on multi-modal visual perception, vison-language model, semi-supervised learning, <i>etc</i>.
    </p>

    <div class="contact-info">
      <div class="contact-item">
        <i class="fa-solid fa-location-dot"></i>
        <span>Tianjin, China</span>
      </div>
      <div class="contact-item">
        <i class="fa-solid fa-envelope"></i>
        <span>sbysbysby123<i class="fa-solid fa-at"></i>gmail.com</span>
      </div>
      <div class="contact-item">
        <a href="https://github.com/BBBBChan" target="_blank" rel="noopener">
          <i class="fa-brands fa-github"></i> Github
        </a>
      </div>
      <div class="contact-item">
        <a href="https://scholar.google.com/citations?user=GvTWUAEAAAAJ&hl=en" target="_blank" rel="noopener">
          <i class="fa-solid fa-graduation-cap"></i> Google Scholar
        </a>
      </div>
      <div class="contact-item">
        <a href="https://www.bbbbchan.com" target="_blank" rel="noopener">
          <i class="fa-solid fa-gift"></i> Blog
        </a>
      </div>
    </div>
  </div>
</div>

<!-- üîπ ÂÆû‰π†ÁªèÂéÜÂå∫ÂüüÔºàÂ∏¶LogoÔºâ -->
<div id="experience">
  <h2 class="section-header">Internship Experience</h2>
  <div class="experience-grid">
    
    <!-- ÂÆû‰π†ÁªèÂéÜ 1: ‰∏äÊµ∑‰∫∫Â∑•Êô∫ËÉΩÂÆûÈ™åÂÆ§ -->
    <div class="exp-card">
      <div class="exp-header">
        <div class="exp-logo-wrapper">
          <!-- üîß ÊõøÊç¢‰∏∫ÂÆûÈôÖlogoË∑ØÂæÑÔºåÂª∫ËÆÆ‰ΩøÁî®ÈÄèÊòéËÉåÊôØPNG -->
          <img src="/assets/img/ailab.png" alt="Shanghai AI Lab" class="exp-logo" 
               onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
          <div style="display:none; width:40px; height:40px; border-radius:8px; background:var(--primary-gradient); align-items:center; justify-content:center; color:white; font-weight:bold; font-size:0.8rem">
            SAIL
          </div>
          <span class="exp-company">Shanghai AI Laboratory</span>
        </div>
        <span class="exp-period">Dec 2025 ‚Äì Present</span>
      </div>
      <div class="exp-role">Research Intern</div>
      <p class="exp-description">
        Working on MLE Agent Workflow, focusing on autonomous agent design, 
        multi-step reasoning, and tool-augmented language models for scientific discovery.
      </p>
      <div class="exp-tags">
        <span class="exp-tag">Agent Workflow</span>
        <span class="exp-tag">MLE</span>
        <span class="exp-tag">Reasoning</span>
      </div>
    </div>

    <!-- ÂÆû‰π†ÁªèÂéÜ 2: ÈÄö‰πâÂÆûÈ™åÂÆ§ -->
    <div class="exp-card">
      <div class="exp-header">
        <div class="exp-logo-wrapper">
          <!-- üîß ÊõøÊç¢‰∏∫ÂÆûÈôÖlogoË∑ØÂæÑ -->
          <img src="/assets/img/tongyi.png" alt="Tongyi Lab" class="exp-logo"
               onerror="this.style.display='none'; this.nextElementSibling.style.display='flex'">
          <div style="display:none; width:40px; height:40px; border-radius:8px; background:linear-gradient(135deg, #ff6b6b, #ee5a24); align-items:center; justify-content:center; color:white; font-weight:bold; font-size:0.7rem">
            ÈÄö‰πâ
          </div>
          <span class="exp-company">Tongyi Lab, Alibaba</span>
        </div>
        <span class="exp-period">Sep 2024 ‚Äì Dec 2025</span>
      </div>
      <div class="exp-role">Research Intern</div>
      <p class="exp-description">
        Researched token compression methods and video understanding techniques 
        for large multimodal models. Contributed to efficient video-LLM architectures 
        and long-context modeling.
      </p>
      <div class="exp-tags">
        <span class="exp-tag">Token Compression</span>
        <span class="exp-tag">Video Understanding</span>
        <span class="exp-tag">Video-LLM</span>
      </div>
    </div>

  </div>
</div>

<!-- Âá∫ÁâàÁâ©Âå∫Âüü -->
<div id="publication">
  <h2 class="section-header">Selected Publications</h2>
  <p class="section-note"><i>* Equal contribution. # Corresponding author.</i></p>
  
  <div class="publications-grid">
    {% for item in page.items %}
    <div class="pub-card">
      <div class="pub-image">
        <img src="{{ item.image.src | absolute_url }}" alt="{{ item.image.alt }}">
      </div>
      <div class="pub-content">
        <h3 class="pub-title">{{ item.title }}</h3>
        <p class="pub-authors">{{ item.author }}</p>
        <p class="pub-venue">{{ item.pubname }}</p>
        
        <div class="pub-links">
          {% if item.paper and item.paper != "" %}
            <a href="{{ item.paper }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-file-pdf"></i> Paper
            </a>
          {% else %}
            <span class="pub-link disabled">Paper</span>
          {% endif %}
          
          {% if item.code and item.code != "" %}
            <a href="{{ item.code }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-brands fa-github"></i> Code
            </a>
          {% endif %}
          
          {% if item.project and item.project != "" %}
            <a href="{{ item.project }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-globe"></i> Project
            </a>
          {% endif %}
          
          {% if item.demo and item.demo != "" %}
            <a href="{{ item.demo }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-play"></i> Demo
            </a>
          {% endif %}
          
          {% if item.hf and item.hf != "" %}
            <a href="{{ item.hf }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-robot"></i> HF
            </a>
          {% endif %}
        </div>
      </div>
    </div>
    {% endfor %}
  </div>
</div>
