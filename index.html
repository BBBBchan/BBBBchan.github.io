---
layout: home
profile_picture:
  src: /assets/img/boyuansun.png
  alt: website picture
items:
- title: Depth Anything at Any Condition
  image:
    src: assets/img/work/depthanythingac_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Modi Jin*,  Bowen Yin, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HVision-NKU/DepthAnythingAC
  paper: https://arxiv.org/abs/2507.01634
  project: https://ghost233lism.github.io/depthanything-AC-page/
  demo: https://huggingface.co/spaces/ghost233lism/DepthAnything-AC
  bibtex: 
- title: LLaVA-Scissor&#58; oken Compression with Semantic Connected Components for Video LLMs
  image:
    src: assets/img/work/llavascissor_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Jiaxing Zhao*,  Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HumanMLLM/LLaVA-Scissor
  paper: https://arxiv.org/abs/2506.21862
  bibtex: 
- title: HumanOmni&#58; A Large Vision-Speech Language Model for Human-Centric Video Understanding
  image:
    src: assets/img/work/humanomni_pipeline.png
    alt: arxiv
  author: Jiaxing Zhao*, Qize Yang*, Yixing Peng*, Detao Bai* Shimin Yao*, <b>Boyuan Sun</b>, Xiang Chen, Shenghao Fu, Weixuan Chen, Xihan Wei, Liefeng Bo#
  pubname: Arxiv preprint 2025
  code: https://github.com/HumanMLLM/HumanOmni
  paper: https://arxiv.org/abs/2501.15111
  bibtex: 
- title: LLaVA-Octopus&#58; Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding
  image:
    src: assets/img/work/octopus_logo.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/Jiaxing-star/LLaVA-Octopus
  paper: https://arxiv.org/abs/2501.05067
  bibtex: 
- title: Facial Dynamics in Video&#58; Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness
  image:
    src: /assets/img/work/DFEC_method.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei
  pubname: Arxiv preprint 2025
  code: https://github.com/Jiaxing-star/FacialDynamic
  paper: https://arxiv.org/abs/2501.07978
  bibtex:
- title: AODRaw&#58; Towards RAW Object Detection in Diverse Conditions
  image:
    src: assets/img/work/aodraw_teaser.png
    alt: arxiv
  author: Zhong-Yu Li, Xin Jin, <b>Boyuan Sun</b>, Chun-Le Guo, Ming-Ming Cheng#
  pubname: IEEE Computer Vision and Pattern Recognition 2025  <b>(CVPR 2025 Highlight)</b>
  code: https://github.com/lzyhha/AODRaw
  paper: https://arxiv.org/abs/2411.15678
  bibtex:
- title: CorrMatch&#58; Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation
  image:
    src: /assets/img/work/corrmatch_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun</b>, Yuqi Yang, Weifeng Yuan, Le Zhang, Ming-Ming Cheng, Qibin Hou#
  pubname: IEEE Computer Vision and Pattern Recognition 2024 <b>(CVPR 2024)</b>
  code: https://github.com/BBBBchan/CorrMatch
  paper: https://arxiv.org/abs/2306.04300
  bibtex:
- title: CamoFormer&#58; Masked Separable Attention for Camouflaged Object Detection
  image:
    src: /assets/img/work/CamoFormer_pipeline.png
    alt: arxiv
  author: Bowen Yin, Xuying Zhang, Qibin Hou, <b>Bo-Yuan Sun</b>, Deng-Ping Fan, & Luc Van Gool.
  pubname: Arxiv preprint 2022
  code: https://github.com/HVision-NKU/CamoFormer
  paper: https://arxiv.org/pdf/2212.06570.pdf
  bibtex:
---


<p>
  Boyuan Sun (孙博远) is currently a 2nd year Ph.D. candidate at Nankai University,
  supervised by Prof. <a href="https://houqb.github.io/">Qibin Hou</a> and Prof. <a href="https://mmcheng.net/cmm">Ming-Ming Cheng</a>. He received his bachelor's degree from the School of Computer Science and Technology at Xidian University in 2021. And now he is taking the Master-Ph.D. combined program in Nankai University.
  His research interests include Computer Vision and Multimodal Large Language Model, particularly focusing on semantic segmentation, semi-supervised learning, vison-language model, <i>etc</i>.
</p>


<p>
  <i class="fa-solid fa-location-dot"></i> Tianjin, China
  <br/>
  <i class="fa-solid fa-envelope"></i>  sbysbysby123<i class="fa-solid fa-at"></i> gmail.com
  <br/>
  <a href="https://github.com/BBBBChan"> <i class="fa-brands fa-github"></i> Github</a>
  &nbsp;&nbsp;&nbsp;
  <a href="https://scholar.google.com/citations?user=GvTWUAEAAAAJ&hl=en"> <i class="fa-solid fa-graduation-cap"></i>Google Scholar</a>
  &nbsp;&nbsp;&nbsp;
  <a href="https://www.bbbbchan.com"><i class="fa-solid fa-gift"></i> Blog</a>


</p>

<div id="publication">
  <h1 class="page-heading">Selected Publications</h1>
  <strong>( * Equal contribution. # Corresponding author. )</strong>
    <br/>
    <table>
    {% for item in page.items %}
      <tr>
        <td width="35%">
          <img
          style="width: 200px"
          src="{{ item.image.src | absolute_url }}"
          alt="{{ item.image.alt }}"
          />
        </td>
        <td width="65%">
          <paper-title> {{ item.title }} </paper-title>
          <br/>
          <paper-info>
            {{ item.author }}
            <br/>
            <em>{{ item.pubname }}</em>
            <br/>
            {% if item.paper and item.paper != "" and item.paper != nil %}
              [<a href="{{ item.paper }}">Paper</a>]
            {% else %}
              [Paper (Coming soon)]
            {% endif %}
            {% if item.code and item.code != "" and item.code != nil %}
              [<a href="{{ item.code }}">Code</a>]
            {% else %}
              [Code]
            {% endif %}
            {% if item.project and item.project != "" and item.project != nil %}
              [<a href="{{ item.project }}">item.project</a>]
            {% endif %}
            {% if item.demo and item.demo != "" and item.demo != nil %}
              [<a href="{{ item.demo }}">item.demo</a>]
            {% endif %}
          </paper-info>
        </td>
      </tr>
    {% endfor %}
  </table>
</div>
