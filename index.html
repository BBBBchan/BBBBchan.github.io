---
layout: home
profile_picture:
  src: /assets/img/boyuansun.png
  alt: website picture
items:
- title: See What I Mean&#58; Aligning Vision and Language Representations for Video Fine-grained Object Understanding
  image:
    src: assets/img/work/swim.png
    alt: arxiv
  author: <b>Boyuan Sun</b>, Bo-Wen Yin, Yuan-Ming Li, Xihan Wei, Qibin Hou
  pubname: IEEE Computer Vision and Pattern Recognition 2026 <b>(CVPR 2026)</b>
  bibtex: 
- title: GeoAgent&#58; Learning to Geolocate Everywhere with Reinforced Geographic Characteristics
  image:
    src: assets/img/work/geoagent.png
    alt: arxiv
  author: Modi Jin, Yiming Zhang, <b>Boyuan Sun</b>, Dingwen Zhang, Ming-Ming Cheng, Qibin Hou 
  pubname: IEEE Computer Vision and Pattern Recognition 2026 <b>(CVPR 2026)</b>
  code: https://github.com/HVision-NKU/GeoAgent  
  paper: https://arxiv.org/abs/2602.12617  
  project: https://ghost233lism.github.io/GeoAgent-page/  
  demo: https://huggingface.co/spaces/ghost233lism/GeoAgent  
  hf: https://huggingface.co/ghost233lism/GeoAgent  
  bibtex: 
- title: Depth Anything at Any Condition
  image:
    src: assets/img/work/depthanythingac_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Modi Jin*,  Bowen Yin, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HVision-NKU/DepthAnythingAC  
  paper: https://arxiv.org/abs/2507.01634  
  project: https://ghost233lism.github.io/depthanything-AC-page/  
  demo: https://huggingface.co/spaces/ghost233lism/DepthAnything-AC  
  hf: https://huggingface.co/ghost233lism/DepthAnything-AC  
  bibtex: 
- title: LLaVA-Scissor&#58; token Compression with Semantic Connected Components for Video LLMs
  image:
    src: assets/img/work/llavascissor_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun*</b>, Jiaxing Zhao*,  Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/HumanMLLM/LLaVA-Scissor  
  paper: https://arxiv.org/abs/2506.21862  
  hf: https://huggingface.co/BBBBCHAN/LLaVA-Scissor-baseline-7B  
  bibtex: 
- title: HumanOmniV2&#58; From Understanding to Omni-Modal Reasoning with Context
  image:
    src: assets/img/work/humanomniv2_pipeline.png
    alt: arxiv
  author: Qize Yang*, Shimin Yao*, Weixuan Chen*, Shenghao Fu, Detao Bai, Jiaxing Zhao, <b>Boyuan Sun</b>, Bowen Yin, Xihan Wei, Jingren Zhou
  pubname: Technical Report
  code: https://github.com/HumanMLLM/HumanOmniV2  
  paper: https://arxiv.org/abs/2506.21277  
  hf: https://huggingface.co/PhilipC/HumanOmniV2  
  bibtex: 
- title: HumanOmni&#58; A Large Vision-Speech Language Model for Human-Centric Video Understanding
  image:
    src: assets/img/work/humanomni_pipeline.png
    alt: arxiv
  author: Jiaxing Zhao*, Qize Yang*, Yixing Peng*, Detao Bai* Shimin Yao*, <b>Boyuan Sun</b>, Xiang Chen, Shenghao Fu, Weixuan Chen, Xihan Wei, Liefeng Bo#
  pubname: Technical Report
  code: https://github.com/HumanMLLM/HumanOmni  
  paper: https://arxiv.org/abs/2501.15111  
  bibtex: 
- title: LLaVA-Octopus&#58; Unlocking Instruction-Driven Adaptive Projector Fusion for Video Understanding
  image:
    src: assets/img/work/octopus_logo.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei, Qibin Hou#
  pubname: Arxiv preprint 2025
  code: https://github.com/Jiaxing-star/LLaVA-Octopus  
  paper: https://arxiv.org/abs/2501.05067  
  bibtex: 
- title: Facial Dynamics in Video&#58; Instruction Tuning for Improved Facial Expression Perception and Contextual Awareness
  image:
    src: /assets/img/work/DFEC_method.png
    alt: arxiv
  author: Jiaxing Zhao*, <b>Boyuan Sun*</b>, Xiang Chen, Xihan Wei
  pubname: Association for the Advancement of Artificial Intelligence 2026 <b>(AAAI 2026)</b>
  code: https://github.com/Jiaxing-star/FacialDynamic  
  paper: https://arxiv.org/abs/2501.07978  
  bibtex:
- title: AODRaw&#58; Towards RAW Object Detection in Diverse Conditions
  image:
    src: assets/img/work/aodraw_teaser.png
    alt: arxiv
  author: Zhong-Yu Li, Xin Jin, <b>Boyuan Sun</b>, Chun-Le Guo, Ming-Ming Cheng#
  pubname: IEEE Computer Vision and Pattern Recognition 2025  <b>(CVPR 2025 Highlight)</b>
  code: https://github.com/lzyhha/AODRaw  
  paper: https://arxiv.org/abs/2411.15678  
  bibtex:
- title: CorrMatch&#58; Label Propagation via Correlation Matching for Semi-Supervised Semantic Segmentation
  image:
    src: /assets/img/work/corrmatch_pipeline.png
    alt: arxiv
  author: <b>Boyuan Sun</b>, Yuqi Yang, Weifeng Yuan, Le Zhang, Ming-Ming Cheng, Qibin Hou#
  pubname: IEEE Computer Vision and Pattern Recognition 2024 <b>(CVPR 2024)</b>
  code: https://github.com/BBBBchan/CorrMatch  
  paper: https://arxiv.org/abs/2306.04300  
  bibtex:
- title: CamoFormer&#58; Masked Separable Attention for Camouflaged Object Detection
  image:
    src: /assets/img/work/CamoFormer_pipeline.png
    alt: arxiv
  author: Bowen Yin, Xuying Zhang, Qibin Hou, <b>Bo-Yuan Sun</b>, Deng-Ping Fan, & Luc Van Gool.
  pubname: Arxiv preprint 2022
  code: https://github.com/HVision-NKU/CamoFormer  
  paper: https://arxiv.org/pdf/2212.06570.pdf  
  bibtex:
---

<style>
  /* 基础样式优化 */
  .profile-section {
    display: flex;
    align-items: flex-start;
    gap: 2rem;
    margin-bottom: 2.5rem;
    flex-wrap: wrap;
  }

  .profile-picture {
    flex-shrink: 0;
  }

  .profile-picture img {
    width: 180px;
    height: 180px;
    border-radius: 50%;
    object-fit: cover;
    border: 4px solid #e0e0e0;
    box-shadow: 0 4px 12px rgba(0,0,0,0.1);
    transition: transform 0.3s ease, box-shadow 0.3s ease;
  }

  .profile-picture img:hover {
    transform: scale(1.05);
    box-shadow: 0 8px 20px rgba(0,0,0,0.15);
  }

  .profile-content {
    flex: 1;
    min-width: 300px;
  }

  .profile-content p {
    line-height: 1.8;
    color: #444;
    margin-bottom: 1rem;
    text-align: justify;
  }

  .contact-info {
    margin-top: 1.5rem;
    padding: 1.5rem;
    background: linear-gradient(135deg, #f5f7fa 0%, #c3cfe2 100%);
    border-radius: 12px;
    display: flex;
    flex-wrap: wrap;
    gap: 1rem;
    align-items: center;
  }

  .contact-info i {
    color: #667eea;
    margin-right: 0.5rem;
    width: 20px;
  }

  .contact-info a {
    color: #667eea;
    text-decoration: none;
    font-weight: 500;
    transition: color 0.3s ease;
    display: inline-flex;
    align-items: center;
    gap: 0.5rem;
  }

  .contact-info a:hover {
    color: #764ba2;
    text-decoration: underline;
  }

  .contact-item {
    display: flex;
    align-items: center;
    gap: 0.5rem;
    margin-bottom: 0.5rem;
  }

  /* 出版物区域样式 */
  #publication {
    margin-top: 3rem;
  }

  .page-heading {
    font-size: 2rem;
    font-weight: 700;
    color: #2d3748;
    margin-bottom: 0.5rem;
    position: relative;
    padding-bottom: 0.5rem;
  }

  .page-heading::after {
    content: '';
    position: absolute;
    bottom: 0;
    left: 0;
    width: 60px;
    height: 4px;
    background: linear-gradient(90deg, #667eea 0%, #764ba2 100%);
    border-radius: 2px;
  }

  .pub-note {
    color: #718096;
    font-size: 0.9rem;
    margin-bottom: 2rem;
    font-style: italic;
  }

  /* 出版物卡片网格 */
  .publications-grid {
    display: grid;
    grid-template-columns: repeat(auto-fill, minmax(600px, 1fr));
    gap: 2rem;
  }

  .pub-card {
    background: white;
    border-radius: 16px;
    overflow: hidden;
    box-shadow: 0 4px 6px rgba(0,0,0,0.07);
    transition: all 0.3s ease;
    border: 1px solid #e2e8f0;
    display: flex;
    flex-direction: column;
  }

  .pub-card:hover {
    transform: translateY(-5px);
    box-shadow: 0 12px 24px rgba(0,0,0,0.12);
  }

  .pub-image {
    width: 100%;
    height: 220px;
    overflow: hidden;
    background: #f7fafc;
    display: flex;
    align-items: center;
    justify-content: center;
  }

  .pub-image img {
    width: 100%;
    height: 100%;
    object-fit: cover;
    transition: transform 0.3s ease;
  }

  .pub-card:hover .pub-image img {
    transform: scale(1.05);
  }

  .pub-content {
    padding: 1.5rem;
    flex: 1;
    display: flex;
    flex-direction: column;
  }

  .pub-title {
    font-size: 1.1rem;
    font-weight: 600;
    color: #2d3748;
    margin-bottom: 0.75rem;
    line-height: 1.4;
  }

  .pub-authors {
    color: #4a5568;
    font-size: 0.9rem;
    margin-bottom: 0.5rem;
    line-height: 1.5;
  }

  .pub-venue {
    color: #667eea;
    font-weight: 600;
    font-size: 0.85rem;
    margin-bottom: 1rem;
  }

  .pub-links {
    display: flex;
    flex-wrap: wrap;
    gap: 0.5rem;
    margin-top: auto;
  }

  .pub-link {
    display: inline-flex;
    align-items: center;
    gap: 0.3rem;
    padding: 0.4rem 0.8rem;
    background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
    color: white;
    text-decoration: none;
    border-radius: 6px;
    font-size: 0.85rem;
    font-weight: 500;
    transition: all 0.3s ease;
    box-shadow: 0 2px 4px rgba(102, 126, 234, 0.3);
  }

  .pub-link:hover {
    transform: translateY(-2px);
    box-shadow: 0 4px 8px rgba(102, 126, 234, 0.4);
  }

  .pub-link.disabled {
    background: #e2e8f0;
    color: #a0aec0;
    cursor: not-allowed;
    box-shadow: none;
  }

  .pub-link.disabled:hover {
    transform: none;
  }

  /* 响应式设计 */
  @media (max-width: 768px) {
    .profile-section {
      flex-direction: column;
      align-items: center;
      text-align: center;
    }

    .profile-content {
      min-width: 100%;
    }

    .profile-content p {
      text-align: left;
    }

    .contact-info {
      justify-content: center;
    }

    .publications-grid {
      grid-template-columns: 1fr;
      gap: 1.5rem;
    }

    .pub-image {
      height: 180px;
    }
  }

  /* 添加平滑滚动 */
  html {
    scroll-behavior: smooth;
  }

  /* 自定义滚动条 */
  ::-webkit-scrollbar {
    width: 10px;
  }

  ::-webkit-scrollbar-track {
    background: #f1f1f1;
  }

  ::-webkit-scrollbar-thumb {
    background: #667eea;
    border-radius: 5px;
  }

  ::-webkit-scrollbar-thumb:hover {
    background: #764ba2;
  }
</style>

<!-- 个人简介区域 -->
<div class="profile-section">
  <div class="profile-picture">
    {% if page.profile_picture %}
    <img src="{{ page.profile_picture.src | absolute_url }}" alt="{{ page.profile_picture.alt }}">
    {% endif %}
  </div>
  <div class="profile-content">
    <p>
      Boyuan Sun (孙博远) is currently a 3rd year Ph.D. candidate at Nankai University,
      supervised by Prof. <a href="https://houqb.github.io/">Qibin Hou</a> and Prof. <a href="https://mmcheng.net/cmm">Ming-Ming Cheng</a>. He received his bachelor's degree from the School of Computer Science and Technology at Xidian University in 2021. And now he is taking the Master-Ph.D. combined program in Nankai University.
      His research interests include Computer Vision and Multimodal Large Language Model, particularly focusing on multi-modal visual perception, vison-language model, semi-supervised learning, <i>etc</i>.
    </p>

    <div class="contact-info">
      <div class="contact-item">
        <i class="fa-solid fa-location-dot"></i>
        <span>Tianjin, China</span>
      </div>
      <div class="contact-item">
        <i class="fa-solid fa-envelope"></i>
        <span>sbysbysby123<i class="fa-solid fa-at"></i>gmail.com</span>
      </div>
      <div class="contact-item">
        <a href="https://github.com/BBBBChan" target="_blank" rel="noopener">
          <i class="fa-brands fa-github"></i> Github
        </a>
      </div>
      <div class="contact-item">
        <a href="https://scholar.google.com/citations?user=GvTWUAEAAAAJ&hl=en" target="_blank" rel="noopener">
          <i class="fa-solid fa-graduation-cap"></i> Google Scholar
        </a>
      </div>
      <div class="contact-item">
        <a href="https://www.bbbbchan.com" target="_blank" rel="noopener">
          <i class="fa-solid fa-gift"></i> Blog
        </a>
      </div>
    </div>
  </div>
</div>

<!-- 出版物区域 -->
<div id="publication">
  <h1 class="page-heading">Selected Publications</h1>
  <p class="pub-note"><i>* Equal contribution. # Corresponding author.</i></p>
  
  <div class="publications-grid">
    {% for item in page.items %}
    <div class="pub-card">
      <div class="pub-image">
        <img src="{{ item.image.src | absolute_url }}" alt="{{ item.image.alt }}">
      </div>
      <div class="pub-content">
        <h3 class="pub-title">{{ item.title }}</h3>
        <p class="pub-authors">{{ item.author }}</p>
        <p class="pub-venue">{{ item.pubname }}</p>
        
        <div class="pub-links">
          {% if item.paper and item.paper != "" %}
            <a href="{{ item.paper }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-file-pdf"></i> Paper
            </a>
          {% else %}
            <span class="pub-link disabled">Paper (Soon)</span>
          {% endif %}
          
          {% if item.code and item.code != "" %}
            <a href="{{ item.code }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-brands fa-github"></i> Code
            </a>
          {% endif %}
          
          {% if item.project and item.project != "" %}
            <a href="{{ item.project }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-globe"></i> Project
            </a>
          {% endif %}
          
          {% if item.demo and item.demo != "" %}
            <a href="{{ item.demo }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-play"></i> Demo
            </a>
          {% endif %}
          
          {% if item.hf and item.hf != "" %}
            <a href="{{ item.hf }}" class="pub-link" target="_blank" rel="noopener">
              <i class="fa-solid fa-robot"></i> HF
            </a>
          {% endif %}
        </div>
      </div>
    </div>
    {% endfor %}
  </div>
</div>
